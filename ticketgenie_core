"""
TicketGenie: Intelligent AMS Ticket Resolution System
Architecture: RAG-based system with multimodal support
"""

import os
from typing import List, Dict, Optional, Any
from datetime import datetime
from enum import Enum
import json
from openai import OpenAI
import numpy as np
from dataclasses import dataclass, asdict

# Initialize OpenAI client
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ==============================================
# 1. DATA MODELS
# ==============================================

class TicketStatus(Enum):
    OPEN = "open"
    IN_PROGRESS = "in_progress"
    RESOLVED = "resolved"
    CLOSED = "closed"

class TicketPriority(Enum):
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"

@dataclass
class Ticket:
    ticket_id: str
    title: str
    description: str
    priority: TicketPriority
    status: TicketStatus
    created_at: datetime
    resolved_at: Optional[datetime]
    resolution: Optional[str]
    category: Optional[str]
    application: Optional[str]
    attachments: List[str]  # File paths or base64 encoded
    tags: List[str]
    
    def to_dict(self):
        data = asdict(self)
        data['priority'] = self.priority.value
        data['status'] = self.status.value
        data['created_at'] = self.created_at.isoformat()
        if self.resolved_at:
            data['resolved_at'] = self.resolved_at.isoformat()
        return data

@dataclass
class SimilarTicket:
    ticket_id: str
    similarity_score: float
    title: str
    resolution: str
    metadata: Dict[str, Any]

# ==============================================
# 2. EMBEDDING SERVICE
# ==============================================

class EmbeddingService:
    """Handles text embedding generation using text-embedding-3-large"""
    
    def __init__(self):
        self.model = "text-embedding-3-large"
        self.dimension = 3072  # text-embedding-3-large dimension
    
    def generate_embedding(self, text: str) -> List[float]:
        """Generate embedding for a single text"""
        try:
            response = client.embeddings.create(
                model=self.model,
                input=text,
                encoding_format="float"
            )
            return response.data[0].embedding
        except Exception as e:
            print(f"Error generating embedding: {e}")
            return []
    
    def generate_embeddings_batch(self, texts: List[str]) -> List[List[float]]:
        """Generate embeddings for multiple texts (batch processing)"""
        try:
            response = client.embeddings.create(
                model=self.model,
                input=texts,
                encoding_format="float"
            )
            return [item.embedding for item in response.data]
        except Exception as e:
            print(f"Error generating batch embeddings: {e}")
            return []
    
    def prepare_ticket_text(self, ticket: Ticket) -> str:
        """Prepare ticket text for embedding"""
        text_parts = [
            f"Title: {ticket.title}",
            f"Description: {ticket.description}",
            f"Category: {ticket.category or 'N/A'}",
            f"Application: {ticket.application or 'N/A'}",
            f"Priority: {ticket.priority.value}",
            f"Tags: {', '.join(ticket.tags)}"
        ]
        return "\n".join(text_parts)

# ==============================================
# 3. VECTOR DATABASE (In-Memory Implementation)
# ==============================================

class VectorDatabase:
    """In-memory vector store with cosine similarity search"""
    
    def __init__(self):
        self.tickets: Dict[str, Ticket] = {}
        self.embeddings: Dict[str, np.ndarray] = {}
    
    def add_ticket(self, ticket: Ticket, embedding: List[float]):
        """Add ticket and its embedding to the database"""
        self.tickets[ticket.ticket_id] = ticket
        self.embeddings[ticket.ticket_id] = np.array(embedding)
    
    def cosine_similarity(self, vec1: np.ndarray, vec2: np.ndarray) -> float:
        """Calculate cosine similarity between two vectors"""
        return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))
    
    def search_similar(self, query_embedding: List[float], top_k: int = 5, 
                      min_similarity: float = 0.7) -> List[SimilarTicket]:
        """Search for similar tickets using cosine similarity"""
        query_vec = np.array(query_embedding)
        similarities = []
        
        for ticket_id, ticket_embedding in self.embeddings.items():
            ticket = self.tickets[ticket_id]
            # Only consider resolved tickets
            if ticket.status in [TicketStatus.RESOLVED, TicketStatus.CLOSED]:
                similarity = self.cosine_similarity(query_vec, ticket_embedding)
                if similarity >= min_similarity:
                    similarities.append({
                        'ticket_id': ticket_id,
                        'similarity': float(similarity),
                        'ticket': ticket
                    })
        
        # Sort by similarity (descending) and return top_k
        similarities.sort(key=lambda x: x['similarity'], reverse=True)
        
        results = []
        for item in similarities[:top_k]:
            ticket = item['ticket']
            results.append(SimilarTicket(
                ticket_id=ticket.ticket_id,
                similarity_score=item['similarity'],
                title=ticket.title,
                resolution=ticket.resolution or "No resolution available",
                metadata={
                    'category': ticket.category,
                    'priority': ticket.priority.value,
                    'resolved_at': ticket.resolved_at.isoformat() if ticket.resolved_at else None
                }
            ))
        
        return results

# ==============================================
# 4. MULTIMODAL DOCUMENT PROCESSOR
# ==============================================

class DocumentProcessor:
    """Process PDFs, images, and structured text using GPT-4 Vision"""
    
    def __init__(self):
        self.supported_formats = ['.pdf', '.png', '.jpg', '.jpeg', '.txt', '.json']
    
    def extract_text_from_image(self, image_base64: str) -> str:
        """Extract text from image using GPT-4 Vision"""
        try:
            response = client.chat.completions.create(
                model="gpt-4o",  # Use vision-capable model
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": "Extract all text from this image. If it's an error message or screenshot, describe the issue in detail."
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{image_base64}"
                                }
                            }
                        ]
                    }
                ],
                max_tokens=1000
            )
            return response.choices[0].message.content
        except Exception as e:
            return f"Error extracting text from image: {e}"
    
    def process_document(self, file_path: str) -> str:
        """Process various document types"""
        ext = os.path.splitext(file_path)[1].lower()
        
        if ext == '.txt':
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read()
        elif ext == '.json':
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return json.dumps(data, indent=2)
        elif ext in ['.png', '.jpg', '.jpeg']:
            # For demo purposes - in production, read and encode the file
            return "Image content would be extracted here"
        elif ext == '.pdf':
            return "PDF content would be extracted here"
        else:
            return f"Unsupported format: {ext}"

# ==============================================
# 5. RESOLUTION ENGINE (GPT-4 Integration)
# ==============================================

class ResolutionEngine:
    """Generate resolution suggestions using GPT-4"""
    
    def __init__(self, embedding_service: EmbeddingService, vector_db: VectorDatabase):
        self.embedding_service = embedding_service
        self.vector_db = vector_db
        self.model = "gpt-4-turbo-preview"
    
    def generate_resolution_suggestions(self, new_ticket: Ticket, 
                                       similar_tickets: List[SimilarTicket]) -> Dict[str, Any]:
        """Generate resolution suggestions based on similar historical tickets"""
        
        # Prepare context from similar tickets
        context_parts = []
        for i, similar in enumerate(similar_tickets, 1):
            context_parts.append(
                f"Similar Ticket {i} (Similarity: {similar.similarity_score:.2%}):\n"
                f"Title: {similar.title}\n"
                f"Resolution: {similar.resolution}\n"
                f"Category: {similar.metadata.get('category', 'N/A')}\n"
            )
        
        context = "\n".join(context_parts)
        
        # Create prompt for GPT-4
        prompt = f"""You are an expert AMS (Application Management Services) ticket resolution assistant.

NEW TICKET:
Title: {new_ticket.title}
Description: {new_ticket.description}
Category: {new_ticket.category or 'N/A'}
Application: {new_ticket.application or 'N/A'}
Priority: {new_ticket.priority.value}

SIMILAR HISTORICAL TICKETS AND THEIR RESOLUTIONS:
{context}

Based on the similar historical tickets, provide:
1. 3 potential resolution suggestions ranked by likelihood of success
2. Step-by-step resolution instructions for the top suggestion
3. Estimated resolution time
4. Any prerequisites or requirements
5. Potential risks or considerations

Format your response as a structured JSON with the following keys:
- suggestions: array of objects with (title, steps, confidence_score, estimated_time)
- recommended_action: the primary suggested resolution
- prerequisites: array of requirements
- risks: array of potential issues
- reasoning: explanation of why these solutions match the ticket
"""

        try:
            response = client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "You are an expert technical support assistant specializing in application management and incident resolution."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=2000,
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content)
            
            # Add explainability information
            result['matched_tickets'] = [
                {
                    'ticket_id': st.ticket_id,
                    'similarity': st.similarity_score,
                    'title': st.title
                }
                for st in similar_tickets
            ]
            
            result['metadata'] = {
                'model_used': self.model,
                'timestamp': datetime.now().isoformat(),
                'ticket_id': new_ticket.ticket_id
            }
            
            return result
            
        except Exception as e:
            return {
                'error': str(e),
                'suggestions': [],
                'recommended_action': 'Manual review required'
            }

# ==============================================
# 6. MAIN TICKET RESOLUTION SYSTEM
# ==============================================

class TicketGenieSystem:
    """Main system orchestrator"""
    
    def __init__(self):
        self.embedding_service = EmbeddingService()
        self.vector_db = VectorDatabase()
        self.document_processor = DocumentProcessor()
        self.resolution_engine = ResolutionEngine(self.embedding_service, self.vector_db)
        self.audit_log = []
    
    def ingest_historical_ticket(self, ticket: Ticket):
        """Ingest a historical ticket into the system"""
        # Generate embedding
        ticket_text = self.embedding_service.prepare_ticket_text(ticket)
        embedding = self.embedding_service.generate_embedding(ticket_text)
        
        # Store in vector database
        self.vector_db.add_ticket(ticket, embedding)
        
        self.audit_log.append({
            'action': 'ingest',
            'ticket_id': ticket.ticket_id,
            'timestamp': datetime.now().isoformat()
        })
    
    def process_new_ticket(self, ticket: Ticket) -> Dict[str, Any]:
        """Process a new ticket and generate resolution suggestions"""
        start_time = datetime.now()
        
        # Generate embedding for new ticket
        ticket_text = self.embedding_service.prepare_ticket_text(ticket)
        embedding = self.embedding_service.generate_embedding(ticket_text)
        
        # Find similar tickets
        similar_tickets = self.vector_db.search_similar(embedding, top_k=5, min_similarity=0.7)
        
        # Generate resolution suggestions
        suggestions = self.resolution_engine.generate_resolution_suggestions(ticket, similar_tickets)
        
        # Calculate processing time
        processing_time = (datetime.now() - start_time).total_seconds()
        
        # Log for audit trail
        self.audit_log.append({
            'action': 'process_new_ticket',
            'ticket_id': ticket.ticket_id,
            'processing_time': processing_time,
            'similar_tickets_found': len(similar_tickets),
            'timestamp': datetime.now().isoformat()
        })
        
        return {
            'ticket_id': ticket.ticket_id,
            'processing_time_seconds': processing_time,
            'similar_tickets': [
                {
                    'ticket_id': st.ticket_id,
                    'similarity_score': st.similarity_score,
                    'title': st.title
                }
                for st in similar_tickets
            ],
            'resolution_suggestions': suggestions,
            'performance_met': processing_time < 2.0  # 2 second SLA
        }
    
    def batch_ingest_tickets(self, tickets: List[Ticket]):
        """Efficiently ingest multiple historical tickets"""
        # Prepare all ticket texts
        ticket_texts = [self.embedding_service.prepare_ticket_text(t) for t in tickets]
        
        # Generate embeddings in batch
        embeddings = self.embedding_service.generate_embeddings_batch(ticket_texts)
        
        # Store all tickets
        for ticket, embedding in zip(tickets, embeddings):
            self.vector_db.add_ticket(ticket, embedding)
        
        print(f"Successfully ingested {len(tickets)} tickets")


# ==============================================
# EXAMPLE USAGE
# ==============================================

if __name__ == "__main__":
    # Initialize system
    system = TicketGenieSystem()
    
    # Example: Create historical tickets
    historical_tickets = [
        Ticket(
            ticket_id="TKT-001",
            title="Application login timeout error",
            description="Users experiencing timeout when logging into the portal. Error message: 'Session timeout exceeded'",
            priority=TicketPriority.HIGH,
            status=TicketStatus.RESOLVED,
            created_at=datetime(2024, 10, 1, 10, 0),
            resolved_at=datetime(2024, 10, 1, 11, 30),
            resolution="Increased session timeout in web.config from 20 to 60 minutes. Cleared application cache and restarted IIS.",
            category="Authentication",
            application="Customer Portal",
            attachments=[],
            tags=["timeout", "login", "session"]
        ),
        Ticket(
            ticket_id="TKT-002",
            title="Database connection pool exhausted",
            description="Application throwing 'Cannot open database' errors during peak hours",
            priority=TicketPriority.CRITICAL,
            status=TicketStatus.RESOLVED,
            created_at=datetime(2024, 10, 5, 14, 0),
            resolved_at=datetime(2024, 10, 5, 15, 0),
            resolution="Increased max pool size from 100 to 200 in connection string. Identified and fixed connection leak in UserService.cs",
            category="Database",
            application="Main Application",
            attachments=[],
            tags=["database", "connection", "performance"]
        )
    ]
    
    # Ingest historical tickets
    print("Ingesting historical tickets...")
    system.batch_ingest_tickets(historical_tickets)
    
    # Create new ticket
    new_ticket = Ticket(
        ticket_id="TKT-NEW-001",
        title="Users cannot login - timeout error",
        description="Multiple users reporting they cannot log in. Getting timeout message after entering credentials.",
        priority=TicketPriority.HIGH,
        status=TicketStatus.OPEN,
        created_at=datetime.now(),
        resolved_at=None,
        resolution=None,
        category="Authentication",
        application="Customer Portal",
        attachments=[],
        tags=["login", "timeout"]
    )
    
    # Process new ticket
    print("\nProcessing new ticket...")
    result = system.process_new_ticket(new_ticket)
    
    print(f"\n{'='*60}")
    print(f"Ticket ID: {result['ticket_id']}")
    print(f"Processing Time: {result['processing_time_seconds']:.3f} seconds")
    print(f"Performance SLA Met: {result['performance_met']}")
    print(f"\nSimilar Tickets Found: {len(result['similar_tickets'])}")
    
    for st in result['similar_tickets']:
        print(f"  - {st['ticket_id']}: {st['title']} (Similarity: {st['similarity_score']:.2%})")
    
    print(f"\nResolution Suggestions:")
    print(json.dumps(result['resolution_suggestions'], indent=2))
